# --- NETWORKING ---
# Max number of incoming connections, default of 128 causes accept() failures if
# large bursts of incoming connections come in.
net.core.somaxconn = 8192

# Max number of pending connections.
net.ipv4.tcp_max_syn_backlog = 8192

# Cap max global socket memory (read & write) at 128MB. 
# This caps autotuning, so make sure it's at least as large as the autotuning below. 
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728

# Let autotuning grow TCP buffers.
# Start at 4KB, increase in steps of 128KB, cap at 128MB
net.ipv4.tcp_rmem = 4096 131072 134217728
net.ipv4.tcp_wmem = 4096 131072 134217728

# Wider ephemeral port range (useful because we open a lot of S3 connections).
net.ipv4.ip_local_port_range = 1024 65535

# Bigger RX backlog, useful for fast (>10GBit) connections
net.core.netdev_max_backlog = 262144

# Keep long-lived client conns healthy; detect dead peers sooner.
net.ipv4.tcp_keepalive_time = 300
net.ipv4.tcp_keepalive_intvl = 60
net.ipv4.tcp_keepalive_probes = 9

# Robustness for PMTU blackholes on S3, avoids stalls on ECMP paths.
net.ipv4.tcp_mtu_probing = 1

# SYN queue sizing is fine; ensure cookies are on in case of bursts.
net.ipv4.tcp_syncookies = 1

# Queueing / Congestion control
# fq congestion control helps with S3 uploads mainly
net.core.default_qdisc = fq

# AWS default recommendation
net.ipv4.tcp_congestion_control = cubic

# --- FILES / MAPS ---

# Raise system-wide FD and vmmap limits. Limits are very large just to be safe.
fs.file-max = 2097152
vm.max_map_count = 1048576

# --- VM / WRITEBACK ---

# Keep kernel dirty pages from growing too large and stalling writeback.
# (We use direct I/O for compaction/flush, but WAL/metadata and other daemons still buffer.)
vm.dirty_background_bytes = 268435456   # 256 MiB
vm.dirty_bytes            = 1073741824  #   1 GiB

# NUMA: prevent zone reclaim surprises on multi-socket boxes.
vm.zone_reclaim_mode = 0

# Only swap when we actually reach near OOM
vm.swappiness = 0
